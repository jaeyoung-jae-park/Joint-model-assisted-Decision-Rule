{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Numerical experiments - Toxic comments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPK9b6ZaVIjf5oDsMI79iUR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaeyoung-jae-park/Joint-model-assisted-Decision-Rule/blob/main/Numerical_experiments_Toxic_comments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMLxzsIkfBD4"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iShTazJ6pSv9"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr5K2JaAmbZr"
      },
      "source": [
        "There are two options to download the dataset of Toxic comments: 1) using Kaggle API; or 2) loading it from your local drive. We encourage you to choose Option 1 because Option 2 takes longer time than the other.\n",
        "\n",
        "If you want to use Kaggle API, you should create new API token. The following document explains how to create it: https://galhever.medium.com/how-to-import-data-from-kaggle-to-google-colab-8160caa11e2.\n",
        "\n",
        "If you want to load it from your local drive, please download the dataset here: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data\n",
        "\n",
        "We only need train.csv for this experiment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cG-ER4cemy-n"
      },
      "source": [
        "### Using Kaggle API\n",
        "Upload your Kaggle API Token and then run the following coddes. \n",
        "\n",
        "Procedure\n",
        "1.   Run the next block.\n",
        "2.   Click the button of \"Choose Files.\"\n",
        "3.   Upload kaggle.json.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "B3HQBYuf7pX8",
        "outputId": "b1b5b534-c481-47eb-9095-ced40375c503"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4e78b701-6ea6-4c91-ab00-1317fd85990e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4e78b701-6ea6-4c91-ab00-1317fd85990e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"jaeyoungpark\",\"key\":\"0560c108cef0bdd5c48cc2c16db24253\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8TF8kjL7vKs"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inhPPkFl7w40"
      },
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv9RECes7ySV",
        "outputId": "0cf00aef-d6df-47ac-b0a6-be1b6c7d95ce"
      },
      "source": [
        "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading train.csv.zip to /content\n",
            " 65% 17.0M/26.3M [00:00<00:01, 9.71MB/s]\n",
            "100% 26.3M/26.3M [00:00<00:00, 30.2MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 38% 9.00M/23.4M [00:00<00:01, 9.03MB/s]\n",
            "100% 23.4M/23.4M [00:00<00:00, 25.4MB/s]\n",
            "Downloading test_labels.csv.zip to /content\n",
            "  0% 0.00/1.46M [00:00<?, ?B/s]\n",
            "100% 1.46M/1.46M [00:00<00:00, 95.8MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.39M [00:00<?, ?B/s]\n",
            "100% 1.39M/1.39M [00:00<00:00, 92.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhH_xojS74Do",
        "outputId": "558e8557-007f-4ea0-e9ba-252f65e50c11"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json  sample_submission.csv.zip\ttest_labels.csv.zip\n",
            "sample_data  test.csv.zip\t\ttrain.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TN0vBYmA765j",
        "outputId": "8b5e8dde-026f-441d-ef86-3f0faad01390"
      },
      "source": [
        "!mkdir toxic\n",
        "!unzip sample_submission.csv.zip -d toxic\n",
        "!unzip test_labels.csv.zip -d toxic\n",
        "!unzip test.csv.zip -d toxic\n",
        "!unzip train.csv.zip -d toxic"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  sample_submission.csv.zip\n",
            "  inflating: toxic/sample_submission.csv  \n",
            "Archive:  test_labels.csv.zip\n",
            "  inflating: toxic/test_labels.csv   \n",
            "Archive:  test.csv.zip\n",
            "  inflating: toxic/test.csv          \n",
            "Archive:  train.csv.zip\n",
            "  inflating: toxic/train.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2bsZX7c8NKM"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train = pd.read_csv(\"/content/toxic/train.csv\") # feel free to change the location"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaitexpMm6DD"
      },
      "source": [
        "### Loading the dataset from your local drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "rhg0PG3Gm4pl",
        "outputId": "8650ca3e-685b-405d-cfa8-78f43c60eac6"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b3f07886-1655-4433-8e26-d517391c4387\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b3f07886-1655-4433-8e26-d517391c4387\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train.csv to train.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-5c2e8a8d365b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     result = _output.eval_js(\n\u001b[1;32m     71\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n\u001b[0;32m---> 72\u001b[0;31m             output_id=output_id))\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'append'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0;31m# JS side uses a generator of promises to process all of the files- some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_uP0cb9n3zB"
      },
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train = pd.read_csv(io.BytesIO(uploaded['train.csv']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ssf5RhT_211"
      },
      "source": [
        "### Checking to load the dataset correctly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PybuLU1oTbM"
      },
      "source": [
        "The codes below show the distribution for each label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrNvliWl3fJA",
        "outputId": "b7030086-7273-44f1-c249-88cf80f6c1c4"
      },
      "source": [
        "np.hstack((train['toxic'].value_counts()[1], \n",
        "           train['severe_toxic'].value_counts()[1], \n",
        "           train['obscene'].value_counts()[1],\n",
        "           train['threat'].value_counts()[1],\n",
        "           train['insult'].value_counts()[1],\n",
        "           train['identity_hate'].value_counts()[1]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([15294,  1595,  8449,   478,  7877,  1405])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw3BeiXx8nJr",
        "outputId": "e954d056-fcf9-4ec4-fc63-6ca2242387f8"
      },
      "source": [
        "train['toxic'].value_counts()/np.sum(train['toxic'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.904156\n",
              "1    0.095844\n",
              "Name: toxic, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODTWLJyH8zAP",
        "outputId": "facc01d1-0c88-4c8b-c379-80791de88365"
      },
      "source": [
        "train['severe_toxic'].value_counts()/np.sum(train['severe_toxic'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.990004\n",
              "1    0.009996\n",
              "Name: severe_toxic, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq06pK3q83sa",
        "outputId": "cf847e11-e3a5-4403-d4b9-0fd5466f5020"
      },
      "source": [
        "train['obscene'].value_counts()/np.sum(train['obscene'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.947052\n",
              "1    0.052948\n",
              "Name: obscene, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYZ6vlyO86cB",
        "outputId": "c6578ade-5995-4c43-ec34-ab042ef62a22"
      },
      "source": [
        "train['threat'].value_counts()/np.sum(train['threat'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.997004\n",
              "1    0.002996\n",
              "Name: threat, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCPe3nSi8-Ob",
        "outputId": "184bb0c3-dd50-4ccc-bed7-14f3ee7707dd"
      },
      "source": [
        "train['insult'].value_counts()/np.sum(train['insult'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.950636\n",
              "1    0.049364\n",
              "Name: insult, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwCvhC2z9BeB",
        "outputId": "249183fe-90b2-4db9-f681-dd89297f3568"
      },
      "source": [
        "train['identity_hate'].value_counts()/np.sum(train['identity_hate'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.991195\n",
              "1    0.008805\n",
              "Name: identity_hate, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "fQd3khaTgYkF",
        "outputId": "28637d66-8f77-41e6-aa8b-2e67a6f0d644"
      },
      "source": [
        "pd.crosstab(train['toxic'], train['obscene'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>obscene</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toxic</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>143754</td>\n",
              "      <td>523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7368</td>\n",
              "      <td>7926</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "obscene       0     1\n",
              "toxic                \n",
              "0        143754   523\n",
              "1          7368  7926"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "qqcONSBGgl2n",
        "outputId": "bc002799-821e-4a5b-fde9-e8d42b3fd568"
      },
      "source": [
        "pd.crosstab(train['toxic'], train['insult'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>insult</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toxic</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>143744</td>\n",
              "      <td>533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7950</td>\n",
              "      <td>7344</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "insult       0     1\n",
              "toxic               \n",
              "0       143744   533\n",
              "1         7950  7344"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFgarPJdonOS"
      },
      "source": [
        "## Label setting\n",
        "Target - toxic comments\n",
        "\n",
        "Auxiliary outcomes - obscene and insult"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-opl1PE_ux8"
      },
      "source": [
        "X = train['comment_text']\n",
        "y = train[['toxic','severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
        "y_aux = train[['toxic', 'obscene', 'insult']]\n",
        "y_aux_agg = pd.concat([y_aux, y_aux.iloc[:,0] * y_aux.iloc[:,1],\n",
        "                        y_aux.iloc[:,0] * y_aux.iloc[:,2]], axis=1)\n",
        "y_tgt = train['toxic']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "16MvhTWOaBEU",
        "outputId": "4a3a289a-0850-4ee8-80fc-72ae0665e37b"
      },
      "source": [
        "y_aux_agg"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>insult</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159566</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159567</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159568</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159569</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159570</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>159571 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        toxic  obscene  insult  0  1\n",
              "0           0        0       0  0  0\n",
              "1           0        0       0  0  0\n",
              "2           0        0       0  0  0\n",
              "3           0        0       0  0  0\n",
              "4           0        0       0  0  0\n",
              "...       ...      ...     ... .. ..\n",
              "159566      0        0       0  0  0\n",
              "159567      0        0       0  0  0\n",
              "159568      0        0       0  0  0\n",
              "159569      0        0       0  0  0\n",
              "159570      0        0       0  0  0\n",
              "\n",
              "[159571 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjNN575Hpd_w"
      },
      "source": [
        "# Hyperparameter settings\n",
        "\n",
        "Neural network structures are defined for the following seven models: Baseline, NN, NN-joint, LDR-NN-joint, LDR-CIDNN, NLDR-NN-joint, and NLDR-CIDNN.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkrz1HHBpswY"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import SGD\n",
        "import tensorflow as tf"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcL4_JBWxlcU"
      },
      "source": [
        "## Baseline\n",
        "\n",
        "A linear decision rule does not have hidden layers. The network consists of an input layer and an output layer.\n",
        "\n",
        "The optimizer is stochastic gradient descent with a learning rate of $10^{-3}$ and a momentum of 0.9. \n",
        "For each training set (9 folds), we further split it and use 20\\% of the data as the validation set to avoid overfitting. \n",
        "The learning rate will decrease and the training may stop early based on the validation loss values. \n",
        "When a validation loss value does not achieve one smaller than the minimum of the last 5 epochs, the learning rate reduces to one tenth of its previous value. Further, although the total number of epochs is 300, the training will stop early, if a loss value smaller than the minimum is not obtained within 10 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng5j7WPGXaAV"
      },
      "source": [
        "def define_Baseline(output_dim):\n",
        "\n",
        "  output_dim = output_dim\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(output_dim, input_shape=(vocab_size,), activation = \"sigmoid\"))\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "def train_Baseline(model, X, y, epochs, batch_size):\n",
        "  if model is None:\n",
        "    if len(y.shape) == 1:\n",
        "      model = define_Baseline(1)\n",
        "    else: model= define_Baseline(y.shape[1])\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "  rl = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer=SGD(learning_rate = 0.001, momentum=0.9), metrics=['accuracy'])\n",
        "  history = model.fit(X , y, batch_size = batch_size, epochs = epochs, validation_split=0.2, callbacks=[es, rl], verbose = 2)\n",
        "  return model, history\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZa97Umvq-8y"
      },
      "source": [
        "## NN and NN-joint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROwHG3dVDSZo"
      },
      "source": [
        "The network includes two fully-connected hidden layers, with 256 and 128 units, respectively, and an additional dropout layer with a drop rate of 0.1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRCZdF-WhLsO"
      },
      "source": [
        "def define_NN(output_dim):\n",
        "\n",
        "  output_dim = output_dim\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(256, input_shape=(vocab_size,), activation='relu'))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(output_dim, activation = \"sigmoid\"))\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "def train_NN(model, X, y, epochs, batch_size):\n",
        "  if model is None:\n",
        "    if len(y.shape) == 1:\n",
        "      model = define_NN(1)\n",
        "    else: model= define_NN(y.shape[1])\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "  rl = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=SGD(learning_rate = 0.001, momentum=0.9), metrics=['accuracy'])\n",
        "  history = model.fit(X , y, batch_size = batch_size, epochs = epochs, validation_split=0.2, callbacks=[es, rl], verbose=2)\n",
        "  return model, history"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7xR0zRMx7iz"
      },
      "source": [
        "## CIDNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hm0ZRp1BGrl"
      },
      "source": [
        "To calculate CIScore correctly, the indicies should match the the positions of auxiliary outcomes. The network structure is identical to NN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrPzER6Kx4dT"
      },
      "source": [
        "def CIScore(y_true, y_pred):\n",
        "  CI_numer = []\n",
        "  CI_numer.append(tf.square((y_pred[:, 3] - y_pred[:, 1] * y_pred[:, 0])))\n",
        "  CI_numer.append(tf.square((y_pred[:, 4] - y_pred[:, 2] * y_pred[:, 0])))\n",
        "  \n",
        "  return tf.reduce_mean(CI_numer[0], axis=-1)/CI_denom[0] + tf.reduce_mean(CI_numer[1], axis=-1)/CI_denom[1] + tf.keras.losses.binary_crossentropy(y_true[:,0], y_pred[:,0])\n",
        "\n",
        "def train_CIDNN(model, X, y, epochs, batch_size):\n",
        "  if model is None:\n",
        "    model = define_NN(y.shape[1])\n",
        "\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "  rl = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
        "\n",
        "  model.compile(loss=CIScore, optimizer=SGD(learning_rate = 0.001, momentum=0.9), metrics=['accuracy'])\n",
        "  history = model.fit(X , y, batch_size = batch_size, epochs = epochs, validation_split=0.2, callbacks=[es, rl], verbose=2)\n",
        "  return model, history\n",
        "\n",
        "  "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9BmSfd-tzId"
      },
      "source": [
        "## Joint-model-assisted linear/nonlinear decision rules (LDR/NLDR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWynxiCwBiA9"
      },
      "source": [
        "The original X and transformed X are concatenate for the input. Except the input layer, the hidden layers and the output layer are identical to the previous models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXRY3xI6y1tG"
      },
      "source": [
        "def define_LDR(input_shape):\n",
        "\n",
        "  output_dim = 1\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(output_dim, input_dim = input_shape, activation = \"sigmoid\"))\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "def train_LDR(model, X, X_extracted, y, epochs, batch_size):\n",
        "  X_transfered = np.hstack((X, X_extracted))\n",
        "\n",
        "  if model is None:\n",
        "    model = define_LDR(X_transfered.shape[1])\n",
        "\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "  rl = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer=SGD(learning_rate = 0.001, momentum=0.9), metrics=['accuracy'])\n",
        "  history = model.fit(X_transfered , y, batch_size = batch_size, epochs = epochs, validation_split=0.2, callbacks=[es,rl], verbose = 2)\n",
        "  return model, history\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbJKpkCjt76J"
      },
      "source": [
        "def define_NLDR(input_shape):\n",
        "\n",
        "  output_dim = 1\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(256, input_shape=(input_shape,), activation='relu'))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(output_dim, activation = \"sigmoid\"))\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "def train_NLDR(model, X, X_extracted, y, epochs, batch_size):\n",
        "  X_transfered = np.hstack((X, X_extracted))\n",
        "\n",
        "  if model is None:\n",
        "    model = define_NLDR(X_transfered.shape[1])\n",
        "\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "  rl = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer=SGD(learning_rate = 0.001, momentum=0.9), metrics=['accuracy'])\n",
        "  history = model.fit(X_transfered , y, batch_size = batch_size, epochs = epochs, validation_split=0.2, callbacks=[es, rl], verbose = 2)\n",
        "  return model, history\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TverzfRaX-Ju"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYXSs-hTsvzE"
      },
      "source": [
        "We use 10-fold cross-validation for the overall procedure. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1QKVGXXX9Uo"
      },
      "source": [
        "X = np.array(X)\n",
        "y_aux_agg = np.array(y_aux_agg)\n",
        "y_tgt = np.array(y_tgt)\n",
        "y_aux = np.array(y_aux)\n",
        "np.random.seed(42)\n",
        "fold_idx = np.random.choice(np.hstack((np.repeat(np.arange(10), int(X.shape[0]/10)), np.arange(X.shape[0] % 10))), size=X.shape[0], replace=False)\n",
        "\n",
        "def split_data(X, y, fold_no):\n",
        "  X_train, X_test, y_train, y_test = X[fold_idx != fold_no], X[fold_idx == fold_no], y[fold_idx != fold_no], y[fold_idx == fold_no]\n",
        "  np.random.seed(fold_no)\n",
        "  shuffle_train = np.random.choice(X_train.shape[0], X_train.shape[0], replace=False)\n",
        "  shuffle_test = np.random.choice(X_test.shape[0], X_test.shape[0], replace=False)\n",
        "  return X_train[shuffle_train], X_test[shuffle_test], y_train[shuffle_train], y_test[shuffle_test]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka7lS0dffK1H"
      },
      "source": [
        "We strongly encourage you to mount Google drive. Again, it takes long time to save and load models from your local drive. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4ItzJJs7fZh",
        "outputId": "1ffd04f1-a7f7-4172-8c3a-09d122e7aace"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KY7m8oVjLmFl"
      },
      "source": [
        "Feel free to change the location where models are saved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCoaGIEEYJQM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "d8ed30a9-c6a0-40bd-e9fd-cb18d70447f2"
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "import keras\n",
        "\n",
        "for fold_no in np.arange(1):\n",
        "  X_train, X_test, y_aux1_train, y_aux1_test = split_data(X, y_aux_agg, fold_no)\n",
        "  X_train, X_test, y_tgt_train, y_tgt_test = split_data(X, y_tgt, fold_no)\n",
        "  y_aux1_train = np.array(y_aux1_train, dtype='float32')\n",
        "\n",
        "  # Create a tf-idf matrix\n",
        "  vocab_size = 5000\n",
        "\n",
        "  tokenizer_obj = Tokenizer(num_words = vocab_size)\n",
        "  tokenizer_obj.fit_on_texts(X_train)\n",
        "\n",
        "  max_length = max([len(s.split()) for s in X])\n",
        "\n",
        "  X_train_tokens = tokenizer_obj.texts_to_matrix(X_train, mode='tfidf')\n",
        "  X_test_tokens = tokenizer_obj.texts_to_matrix(X_test, mode='tfidf')\n",
        "\n",
        "  # Baseline\n",
        "  model_Baseline, history_Baseline = train_Baseline(model = None, X= X_train_tokens, y = y_tgt_train, epochs = 300, batch_size = 256)\n",
        "  model_Baseline.save(\"/content/drive/MyDrive/Can_a_joint_model_assist_target_label_prediction/Toxic_comments/model_Baseline_\"+str(fold_no))\n",
        "  del model_Baseline\n",
        "  keras.backend.clear_session()\n",
        "  \n",
        "  # NN\n",
        "  model_NN, history_NN = train_NN(model = None, X= X_train_tokens, y = y_tgt_train, epochs = 300, batch_size = 256)\n",
        "  model_NN.save(\"/content/drive/MyDrive/Can_a_joint_model_assist_target_label_prediction/Toxic_comments/model_NN_\"+str(fold_no))\n",
        "  del model_NN\n",
        "  keras.backend.clear_session()\n",
        "\n",
        "  # NN-joint\n",
        "  model_NN_joint, history_NN_joint = train_NN(model = None, X= X_train_tokens, y = y_aux1_train[:,0:3], epochs = 300, batch_size = 256)\n",
        "  model_NN_joint.save(\"/content/drive/MyDrive/Can_a_joint_model_assist_target_label_prediction/Toxic_comments/model_NN_joint_\"+str(fold_no))\n",
        "  del model_NN_joint\n",
        "  keras.backend.clear_session()\n",
        "\n",
        "\n",
        "  # CIDNN\n",
        "\n",
        "  ## the denominator of the first term of CIScore\n",
        "  sample_size = y_aux1_train.shape[0]\n",
        "  CI_denom = []\n",
        "  CI_denom.append((tf.square(tf.reduce_sum(y_aux1_train[:,3], axis=-1)/sample_size - \n",
        "                          tf.reduce_sum(y_aux1_train[:,1], axis=-1)/sample_size * \n",
        "                          tf.reduce_sum(y_aux1_train[:,0], axis=-1)/sample_size)))\n",
        "  CI_denom.append((tf.square(tf.reduce_sum(y_aux1_train[:,4], axis=-1)/sample_size - \n",
        "                          tf.reduce_sum(y_aux1_train[:,2], axis=-1)/sample_size * \n",
        "                          tf.reduce_sum(y_aux1_train[:,0], axis=-1)/sample_size)))\n",
        "\n",
        "  ## training the model\n",
        "  model_CIDNN, history_CIDNN = train_CIDNN(model = None, X = X_train_tokens, y = y_aux1_train, epochs=300, batch_size = 256)\n",
        "  model_CIDNN.save(\"/content/drive/MyDrive/Can_a_joint_model_assist_target_label_prediction/Toxic_comments/model_CIDNN_\"+str(fold_no))\n",
        "  del model_CIDNN\n",
        "\n",
        "\n",
        "  # Extracting transformed features from the CIDNN\n",
        "  model_CIDNN = keras.models.load_model('/content/drive/MyDrive/Can_a_joint_model_assist_target_label_prediction/Toxic_comments/model_CIDNN_'+str(fold_no), compile=False)\n",
        "  extraction1 = Model(inputs=model_CIDNN.inputs, outputs=model_CIDNN.layers[-2].output)\n",
        "  extracted_features1 = extraction1.predict(X_train_tokens)\n",
        "  del model_CIDNN, extraction1\n",
        "  keras.backend.clear_session()\n",
        "  \n",
        "  # LDR-CIDNN\n",
        "  model_LDR_CIDNN, history_LDR_CIDNN = train_LDR(model = None, X= X_train_tokens, X_extracted = extracted_features1, y = y_tgt_train, epochs= 300, batch_size = 256)\n",
        "  model_LDR_CIDNN.save(\"/content/drive/MyDrive/Can_a_joint_model_assist_target_label_prediction/Toxic_comments/model_LDR_CIDNN_\"+str(fold_no))\n",
        "  del model_LDR_CIDNN\n",
        "  keras.backend.clear_session()\n",
        "\n",
        "  # NLDR-CIDNN\n",
        "  model_NLDR_CIDNN, history_NLDR_CIDNN = train_NLDR(model = None, X= X_train_tokens, X_extracted = extracted_features1, y = y_tgt_train, epochs= 300, batch_size = 256)\n",
        "  model_NLDR_CIDNN.save(\"/content/drive/MyDrive/Can_a_joint_model_assist_target_label_prediction/Toxic_comments/model_NLDR_CIDNN_\"+str(fold_no))\n",
        "  del model_NLDR_CIDNN, extracted_features1\n",
        "  keras.backend.clear_session()\n",
        "\n",
        "  \n",
        "  # Extracting transformed features from the joint model\n",
        "  model_NN_joint = keras.models.load_model('/content/drive/MyDrive/Can_a_joint_model_assist_target_label_prediction/Toxic_comments/model_NN_joint_'+str(fold_no), compile=False)\n",
        "  extraction_ce1 = Model(inputs=model_NN_joint.inputs, outputs=model_NN_joint.layers[-2].output)\n",
        "  extracted_features_ce1 = extraction_ce1.predict(X_train_tokens)\n",
        "  del model_NN_joint, extraction_ce1\n",
        "  keras.backend.clear_session()\n",
        "\n",
        "  # LDR-NN-joint\n",
        "  model_LDR_NN_joint, history_LDR_NN_joint = train_LDR(model = None, X= X_train_tokens, X_extracted = extracted_features_ce1, y = y_tgt_train, epochs= 300, batch_size = 256)\n",
        "  model_LDR_NN_joint.save(\"/content/drive/MyDrive/Can_a_joint_model_assist_target_label_prediction/Toxic_comments/model_LDR_NN_joint_\"+str(fold_no))\n",
        "  del model_LDR_NN_joint\n",
        "  keras.backend.clear_session()\n",
        "\n",
        "  # NLDR-NN-joint\n",
        "  model_NLDR_NN_joint, history_NLDR_NN_joint = train_NLDR(model = None, X = X_train_tokens, X_extracted = extracted_features_ce1, y = y_tgt_train, epochs = 300, batch_size = 256)\n",
        "  model_NLDR_NN_joint.save(\"/content/drive/MyDrive/Can_a_joint_model_assist_target_label_prediction/Toxic_comments/model_NLDR_NN_joint_\"+str(fold_no))\n",
        "  del model_NLDR_NN_joint\n",
        "  keras.backend.clear_session()\n",
        "\n",
        "  del X_train, X_test, y_aux1_train, y_aux1_test, y_tgt_train, y_tgt_test, tokenizer_obj, X_train_tokens, X_test_tokens"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-6024b076161b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mmodel_CIDNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_CIDNN' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3PhDClwjwQ0"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFuhoIZ8Ke-8"
      },
      "source": [
        "Evaluate models with the following metrics: AUC, accuracy, F1 score. If you do not train models above, please upload the trained models we provide. \n",
        "\n",
        "We provide the trained models. Please find them here: https://drive.google.com/drive/folders/1sQaV1LYvmgDbtzhhtBFMavwcJyAI_C-H?usp=sharing. You can download them or copy them to your drive. The following link explains how to copy the shared folder to your drive: https://stackoverflow.com/questions/54351852/accessing-shared-with-me-with-colab\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_LRl2gMT63Z"
      },
      "source": [
        "# if you want to load models from your local drive, please use this code\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFX_Lg-_8uZC"
      },
      "source": [
        "import keras \n",
        "from keras.models import Model\n",
        "from sklearn import metrics\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "scores = {}\n",
        "\n",
        "for fold_no in np.arange(1):\n",
        "  X_train, X_test, y_aux1_train, y_aux1_test = split_data(X, y_aux_agg, fold_no)\n",
        "  X_train, X_test, y_tgt_train, y_tgt_test = split_data(X, y_tgt, fold_no)\n",
        "  y_aux1_train = np.array(y_aux1_train, dtype='float32')\n",
        "\n",
        "  vocab_size = 5000\n",
        "\n",
        "  tokenizer_obj = Tokenizer(num_words = vocab_size)\n",
        "  tokenizer_obj.fit_on_texts(X_train)\n",
        "\n",
        "  max_length = max([len(s.split()) for s in X])\n",
        "\n",
        "  X_train_tokens = tokenizer_obj.texts_to_matrix(X_train, mode='tfidf')\n",
        "  X_test_tokens = tokenizer_obj.texts_to_matrix(X_test, mode='tfidf')\n",
        "\n",
        "  model_Baseline = keras.models.load_model('/content/drive/MyDrive/Can_a_joint_model_assist_target_label_prediction/Toxic_comments/model_Baseline_'+str(fold_no))\n",
        "  model_NN = keras.models.load_model('/content/drive/MyDrive/Can_a_joint_model_assist_target_label_prediction/Toxic_comments/model_NN_'+str(fold_no))\n",
        "  model_NN_joint = keras.models.load_model('/content/drive/MyDrive/Can_a_joint_model_assist_target_label_prediction/Toxic_comments/model_NN_joint_'+str(fold_no))\n",
        "  model_CIDNN = keras.models.load_model('/content/drive/MyDrive/Can_a_joint_model_assist_target_label_prediction/Toxic_comments/model_CIDNN_'+str(fold_no), compile=False)\n",
        "  model_NLDR_CIDNN = keras.models.load_model('/content/drive/MyDrive/Can_a_joint_model_assist_target_label_prediction/Toxic_comments/model_NLDR_CIDNN_'+str(fold_no))\n",
        "  model_LDR_CIDNN = keras.models.load_model('/content/drive/MyDrive/Can_a_joint_model_assist_target_label_prediction/Toxic_comments/model_LDR_CIDNN_'+str(fold_no))\n",
        "  model_NLDR_NN_joint = keras.models.load_model('/content/drive/MyDrive/Can_a_joint_model_assist_target_label_prediction/Toxic_comments/model_NLDR_NN_joint_'+str(fold_no))\n",
        "  model_LDR_NN_joint = keras.models.load_model('/content/drive/MyDrive/Can_a_joint_model_assist_target_label_prediction/Toxic_comments/model_LDR_NN_joint_'+str(fold_no))\n",
        "\n",
        "\n",
        "  predicted_Baseline = model_Baseline.predict(X_test_tokens)\n",
        "  predicted_NN = model_NN.predict(X_test_tokens)\n",
        "  predicted_NN_joint = model_NN_joint.predict(X_test_tokens)[:,0]\n",
        "  \n",
        "  #CIDNN\n",
        "  extraction = Model(inputs=model_CIDNN.inputs, outputs=model_CIDNN.layers[-2].output)\n",
        "  predicted_extract = extraction.predict(X_test_tokens)\n",
        "  predicted_LDR_CIDNN = model_LDR_CIDNN.predict(np.hstack((X_test_tokens, predicted_extract)))\n",
        "  predicted_NLDR_CIDNN = model_NLDR_CIDNN.predict(np.hstack((X_test_tokens, predicted_extract)))\n",
        "  \n",
        "  #NN-joint\n",
        "  extraction_NN_joint = Model(inputs=model_NN_joint.inputs, outputs=model_NN_joint.layers[-2].output)\n",
        "  predicted_extract_NN_joint = extraction_NN_joint.predict(X_test_tokens)\n",
        "  predicted_LDR_NN_joint = model_LDR_NN_joint.predict(np.hstack((X_test_tokens, predicted_extract_NN_joint)))\n",
        "  predicted_NLDR_NN_joint = model_NLDR_NN_joint.predict(np.hstack((X_test_tokens, predicted_extract_NN_joint)))\n",
        "  \n",
        "  auc_Baseline = metrics.roc_auc_score(y_tgt_test, (predicted_Baseline).reshape(-1))\n",
        "  auc_NN = metrics.roc_auc_score(y_tgt_test, (predicted_NN).reshape(-1))\n",
        "  auc_NN_joint = metrics.roc_auc_score(y_tgt_test, (predicted_NN_joint).reshape(-1))\n",
        "  auc_LDR_CIDNN = metrics.roc_auc_score(y_tgt_test, (predicted_LDR_CIDNN).reshape(-1))\n",
        "  auc_NLDR_CIDNN = metrics.roc_auc_score(y_tgt_test, (predicted_NLDR_CIDNN).reshape(-1))\n",
        "  auc_NLDR_NN_joint = metrics.roc_auc_score(y_tgt_test, (predicted_NLDR_NN_joint).reshape(-1))\n",
        "  auc_LDR_NN_joint = metrics.roc_auc_score(y_tgt_test, (predicted_LDR_NN_joint).reshape(-1))\n",
        "\n",
        "  acc_Baseline = np.mean(((predicted_Baseline > 0.5) *1).reshape(-1) == y_tgt_test)\n",
        "  acc_NN = np.mean(((predicted_NN > 0.5) *1).reshape(-1) == y_tgt_test)\n",
        "  acc_NN_joint = np.mean(((predicted_NN_joint > 0.5) *1).reshape(-1) == y_tgt_test)\n",
        "  acc_LDR_CIDNN = np.mean(((predicted_LDR_CIDNN > 0.5) *1).reshape(-1) == y_tgt_test)\n",
        "  acc_NLDR_CIDNN = np.mean(((predicted_NLDR_CIDNN > 0.5) *1).reshape(-1) == y_tgt_test)\n",
        "  acc_LDR_NN_joint = np.mean(((predicted_LDR_NN_joint > 0.5) *1).reshape(-1) == y_tgt_test)\n",
        "  acc_NLDR_NN_joint = np.mean(((predicted_NLDR_NN_joint > 0.5) *1).reshape(-1) == y_tgt_test)\n",
        "\n",
        "  f1_Baseline = metrics.f1_score(y_tgt_test, ((predicted_Baseline>0.5) *1).reshape(-1))\n",
        "  f1_NN = metrics.f1_score(y_tgt_test, ((predicted_NN>0.5) *1).reshape(-1))\n",
        "  f1_NN_joint = metrics.f1_score(y_tgt_test, ((predicted_NN_joint>0.5) *1).reshape(-1))\n",
        "  f1_LDR_CIDNN = metrics.f1_score(y_tgt_test, ((predicted_LDR_CIDNN>0.5)*1).reshape(-1))\n",
        "  f1_NLDR_CIDNN = metrics.f1_score(y_tgt_test, ((predicted_NLDR_CIDNN>0.5)*1).reshape(-1))\n",
        "  f1_LDR_NN_joint = metrics.f1_score(y_tgt_test, ((predicted_LDR_NN_joint>0.5)*1).reshape(-1))\n",
        "  f1_NLDR_NN_joint = metrics.f1_score(y_tgt_test, ((predicted_NLDR_NN_joint>0.5)*1).reshape(-1))\n",
        "\n",
        "  scores[fold_no] = np.array([auc_Baseline, auc_NN, auc_NN_joint, auc_LDR_NN_joint, auc_LDR_CIDNN, auc_NLDR_NN_joint, auc_NLDR_CIDNN,  \n",
        "                              acc_Baseline, acc_NN, acc_NN_joint, acc_LDR_NN_joint, acc_LDR_CIDNN, acc_NLDR_NN_joint, acc_NLDR_CIDNN,  \n",
        "                              f1_Baseline, f1_NN, f1_NN_joint, f1_LDR_NN_joint, f1_LDR_CIDNN, f1_NLDR_NN_joint, f1_NLDR_CIDNN])\n",
        "  del X_train, X_test, y_aux1_train, y_aux1_test, y_tgt_train, y_tgt_test, tokenizer_obj, X_train_tokens, X_test_tokens\n",
        "\n",
        "scores_final = np.vstack(scores.values())\n",
        "\n",
        "scores_final = pd.DataFrame(scores_final, columns = ['auc_Baseline','auc_NN', 'auc_NN_joint', 'auc_LDR_NN_joint', 'auc_LDR_CIDNN', 'auc_NLDR_NN_joint', 'auc_NLDR_CIDNN',\n",
        "                                                     'acc_Baseline','acc_NN', 'acc_NN_joint', 'acc_LDR_NN_joint', 'acc_LDR_CIDNN','acc_NLDR_NN_joint', 'acc_NLDR_CIDNN',\n",
        "                                                     'f1_Baseline','f1_NN', 'f1_NN_joint', 'f1_LDR_NN_joint','f1_LDR_CIDNN','f1_NLDR_NN_joint', 'f1_NLDR_CIDNN'])\n",
        "# scores_final.to_csv('/content/drive/MyDrive/Can_a_joint_model_assist_target_label_prediction/Toxic_comments/scores_final.csv')"
      ],
      "execution_count": 47,
      "outputs": []
    }
  ]
}